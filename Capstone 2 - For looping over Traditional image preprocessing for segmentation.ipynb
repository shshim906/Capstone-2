{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The purpose of the Capstone 2 project is to determine whether or not the lesion in an image is malignant or not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script loops over the traditional image processing method to produce statistics on malignant and benign lesions ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: image(.jpg)<br>\n",
    "Output: dictionary (imgname:original img, segmented image,largest contour,area of the largest contour,mask used for segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/seo/environments/my_env/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%run functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_rgb_channels(image):\n",
    "    \"\"\"Split the target image into its red, green and blue channels.image - a numpy array of shape (rows, columns, 3).\n",
    "    output - three numpy arrays of shape (rows, columns) and dtype same as\n",
    "    image, containing the corresponding channels.\n",
    "    \"\"\"\n",
    "    red = image[:,:,2]\n",
    "    green = image[:,:,1]\n",
    "    blue = image[:,:,0]\n",
    "    return red, green, blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_bound(image, angle,cX,cY):\n",
    "    # grab the dimensions of the image\n",
    "    (h, w) = image.shape[:2] \n",
    "    # grab the rotation matrix, then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    " \n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    " \n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    " \n",
    "    # perform the actual rotation and return the image\n",
    "    return cv2.warpAffine(image, M, (nW, nH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(imageA, imageB):\n",
    "    # the 'Mean Squared Error' between the two images is the\n",
    "    # sum of the squared difference between the two images;\n",
    "    # NOTE: the two images must have the same dimension\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(maxContour)\n",
    "    # return the MSE, the lower the error, the more \"similar\"\n",
    "    # the two images are\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mag_ang(img):\n",
    "\n",
    "    \"\"\"\n",
    "    Gets image gradient (magnitude) and orientation (angle)\n",
    "\n",
    "    Args:\n",
    "        img\n",
    "\n",
    "    Returns:\n",
    "        Gradient, orientation\n",
    "    \"\"\"\n",
    "\n",
    "    img = np.sqrt(img)\n",
    "\n",
    "    gx = cv2.Sobel(np.float32(img), cv2.CV_32F, 1, 0)\n",
    "    gy = cv2.Sobel(np.float32(img), cv2.CV_32F, 0, 1)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(gx, gy)\n",
    "\n",
    "    return mag, ang, gx, gy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_dict=dict()\n",
    "blue_dict=dict()\n",
    "green_dict=dict()\n",
    "red_dict=dict()\n",
    "border_dict=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/seo/ISIC_DATA\"\n",
    "\n",
    "import pickle\n",
    "name=\"isic_data\"\n",
    "df=pickle.load(open(name,\"rb\"))\n",
    "\n",
    "import cv2\n",
    "\n",
    "filelist=os.listdir(path)\n",
    "pics=[file for file in filelist if (file.endswith(\".jpeg\") or file.endswith(\".png\")) and file.startswith(\"ISIC\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "for i in range(j,len(pics)):\n",
    "\n",
    "    imgname=pics[i]\n",
    "    filename=path+'/'+pics[i]\n",
    "    \n",
    "    label=imgname.split('.')[0]\n",
    "\n",
    "    orig_img=cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "    img=orig_img\n",
    "\n",
    "    # normalize image\n",
    "\n",
    "    norm_image = cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "\n",
    "    img=norm_image\n",
    "\n",
    "    # split image into RGB channels\n",
    "\n",
    "\n",
    "\n",
    "    r,g,b=split_into_rgb_channels(img)\n",
    "\n",
    "    \n",
    "    #reduce noise\n",
    "\n",
    "    # Do some denoising on blue channel because that usually gives best contrast\n",
    "    gaussian = cv2.GaussianBlur(b,(3,3),0)\n",
    "\n",
    "\n",
    "    #find edge & image segmentation\n",
    "\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    th, threshed = cv2.threshold(gaussian, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    erosion = cv2.erode(threshed,kernel,iterations = 3)\n",
    "    dilation = cv2.morphologyEx(erosion, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    cnts, hierarchy=cv2.findContours(erosion,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE )\n",
    "    cnts = sorted(cnts, key=cv2.contourArea)\n",
    "    H,W = img.shape[:2]\n",
    "    \n",
    "    maxContour = 0\n",
    "\n",
    "    for contour in cnts:\n",
    "        cv2.drawContours(img,contour,-1,(255,0,0),-1)\n",
    "        contourSize = cv2.contourArea(contour)\n",
    "        if contourSize > maxContour:\n",
    "            maxContour = contourSize\n",
    "            maxContourData = contour\n",
    "        #if contour\n",
    "    cv2.drawContours(img,[contour],-1,(255,0,0),-1)\n",
    "\n",
    "    # Create mask and do bitwise-op\n",
    "    \n",
    "    mask = np.zeros(img.shape[:2],np.uint8)\n",
    "    cv2.drawContours(mask, [contour],-1, 255, -1)\n",
    "    \n",
    "    #area = cv2.contourArea(contour)\n",
    "    dst = cv2.bitwise_and(gaussian, gaussian, mask=mask)\n",
    "    \n",
    "    fourcorners=[(0,0),(img.shape[:2][1]-1,0),(0,img.shape[:2][0]-1),(img.shape[:2][1]-1,img.shape[:2][0]-1)]\n",
    "\n",
    "    orig_cnts=cnts\n",
    "    new_cnts=list()\n",
    "    for j in range(len(cnts)):\n",
    "        try:\n",
    "            contour=cnts[j]\n",
    "            bunch=[tuple(contour[num][0]) for num in range(len(contour))]\n",
    "            y_min=min(bunch, key=lambda t: t[0])[0]\n",
    "            y_max=max(bunch, key=lambda t: t[0])[0]\n",
    "            x_min=min(bunch, key=lambda t: t[1])[1]\n",
    "            x_max=max(bunch, key=lambda t: t[1])[1]\n",
    "\n",
    "            y_count=0\n",
    "            x_count=0\n",
    "\n",
    "            for num in bunch:\n",
    "                if num[0]==x_min:\n",
    "                    x_count=x_count+1\n",
    "                if num[0]==x_max:\n",
    "                    x_count=x_count+1\n",
    "                if num[1]==y_min:\n",
    "                    y_count=y_count+1\n",
    "                if num[1]==y_max:\n",
    "                    y_count=y_count+1\n",
    "            if (x_count>round(img.shape[:2][0]*0.6)) or (y_count>round(img.shape[:2][1]*0.6)):\n",
    "                cnts.pop(j)\n",
    "        except:\n",
    "            continue\n",
    "    #retread to check if there are removed contour\n",
    "    for contour in cnts:\n",
    "        cv2.drawContours(img,contour,-1,(255,0,0),-1)\n",
    "        contourSize = cv2.contourArea(contour)\n",
    "        if contourSize > maxContour:\n",
    "            maxContour = contourSize\n",
    "            maxContourData = contour\n",
    "        #if contour\n",
    "    cv2.drawContours(img,[contour],-1,(255,0,0),-1)\n",
    "    ## Create mask and do bitwise-op\n",
    "    mask = np.zeros(img.shape[:2],np.uint8)\n",
    "    cv2.drawContours(mask, [contour],-1, 255, -1)\n",
    "    #area = cv2.contourArea(contour)\n",
    "    dst = cv2.bitwise_and(gaussian, gaussian, mask=mask)\n",
    "\n",
    "   \n",
    "    #Check for symmetry: bigger value more malignant\n",
    "\n",
    "    # get angle and center for rotation\n",
    "    (a,b),(MA,ma),angle = cv2.fitEllipse(maxContourData)\n",
    "    a=int(a)\n",
    "    b=int(b)\n",
    "\n",
    "\n",
    "    rotated_roi=rotate_bound(dst,angle,a,b)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "    imageO=rotated_roi\n",
    "    imageLR=np.fliplr(rotated_roi)\n",
    "    imageUD=np.flipud(rotated_roi)\n",
    "\n",
    "    lr=mse(rotated_roi, np.fliplr(rotated_roi),maxContour)\n",
    "    ud=mse(rotated_roi, np.flipud(rotated_roi),maxContour)\n",
    "\n",
    "    symmetry_dict[label]=(lr+ud)/2\n",
    "\n",
    "    #Check Color: bigger value more malignant\n",
    "\n",
    "    colorcheck = cv2.bitwise_and(orig_img, orig_img, mask=mask)\n",
    "    #plt.imshow(colorcheck)\n",
    "\n",
    "    color = ('b','g','r')\n",
    "    #fig=plt.figure()\n",
    "    zerovalues=list()\n",
    "    #ax=fig.add_subplot(2,1,1)\n",
    "    b_list=[]\n",
    "    g_list=[]\n",
    "    r_list=[]\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([colorcheck],[i],None,[256],[0,256])\n",
    "        #ax.plot(histr,color = col)\n",
    "        zerovalues.append(histr[0])\n",
    "        histr=histr[1:]\n",
    "        #plt.xlim([0,255])\n",
    "        #ax.set_yscale('log')\n",
    "        if col=='b':\n",
    "            blue_dict[label]=histr.std()\n",
    "        if col=='g':\n",
    "            green_dict[label]=histr.std()\n",
    "        if col=='r':\n",
    "            red_dict[label]=histr.std()\n",
    "        #print(histr.std())\n",
    "    #plt.show()\n",
    "    #zerovalues\n",
    "    #print(type(std_list))\n",
    "    #print(std_list)\n",
    "\n",
    "    #Check border\n",
    "\n",
    "\n",
    "\n",
    "    h=20; w=20\n",
    "    tots_gradient=[]\n",
    "    for point in maxContourData[:,0]:\n",
    "        x=point[0]\n",
    "        y=point[1]\n",
    "        #print(x,y)\n",
    "        y1=y-h; y2=y+h\n",
    "        x1=x-w; x2=x+w\n",
    "        if y1<0:\n",
    "            y1=0\n",
    "        if y2>H:\n",
    "            y2=H\n",
    "        if x1<0:\n",
    "            x1=0\n",
    "        if x2>W:\n",
    "            x2=W\n",
    "        #print(x1,y1,x2,y2)\n",
    "        crop_img = orig_img[:,:,0][y1:y2, x1:x2].copy()\n",
    "        mag,ang,gx,gy=get_mag_ang(crop_img)\n",
    "        tots_gradient.append(mag.mean())\n",
    "\n",
    "    border_dict[label]=np.mean(tots_gradient)\n",
    "    j=j+1\n",
    "\n",
    "\n",
    "print(symmetry_dict,blue_dict,border_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sym_data.pickle', 'wb') as f:\n",
    "    pickle.dump(symmetry_dict, f)\n",
    "with open('b_data.pickle', 'wb') as f:\n",
    "    pickle.dump(blue_dict, f)\n",
    "with open('g_data.pickle', 'wb') as f:\n",
    "    pickle.dump(green_dict, f)\n",
    "with open('r_data.pickle', 'wb') as f:\n",
    "    pickle.dump(red_dict, f)\n",
    "with open('bor_data.pickle', 'wb') as f:\n",
    "    pickle.dump(border_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
